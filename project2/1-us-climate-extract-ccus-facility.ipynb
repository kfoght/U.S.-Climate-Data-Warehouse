{
  "cells": [
    {
      "cell_type": "code",
      "id": "AuWxWylpMBcvL7WcSGgcMCD7",
      "metadata": {
        "tags": [],
        "id": "AuWxWylpMBcvL7WcSGgcMCD7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4db636e0-a775-4320-d113-cb0b89e49de0"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part\n",
        "from google.cloud import storage\n",
        "from google.cloud.storage import transfer_manager\n",
        "\n",
        "# Configuration\n",
        "project_id = \"kiaraerica\"\n",
        "location = \"us-central1\"\n",
        "bucket_name = \"us_climate\"\n",
        "raw_folder = \"initial-loads/ccus_facility/raw/\"\n",
        "llm_folder = \"initial-loads/ccus_facility/llm_text/\"\n",
        "model_name = \"gemini-1.5-flash-001\"\n",
        "\n",
        "# Updated prompt for CCS data extraction\n",
        "prompt = \"\"\"Extract structured Carbon Capture and Storage (CCS) facility data from this document.\n",
        "Identify and return the following fields:\n",
        "1. Facility Number (ID) - the number assigned to each facility in the dataset.\n",
        "2. Facility Name\n",
        "3. Organization\n",
        "4. City\n",
        "5. State\n",
        "6. Category (e.g., Capture, Storage, Transport)\n",
        "7. Status (e.g., Operational, In Development, Proposed, Under Construction, Inactive)\n",
        "8. Industry (e.g., Power Generation, Hydrogen Production, Ethanol Production)\n",
        "\n",
        "Return each facility as a separate JSON object, one per line (NDJSON format), like:\n",
        "{\"id\": \"integer\", \"facility\": \"string\", \"organization\": \"string\", \"city\": \"string\", \"state\": \"string\", \"category\": \"string\", \"status\": \"string\", \"industry\": \"string\"}\n",
        "\n",
        "Do not return an array. Do not add extra text. Return only NDJSON.\n",
        "\"\"\"\n",
        "\n",
        "def extract():\n",
        "    \"\"\"Extracts structured CCS facility data from all PDFs in `raw_folder` using Gemini and outputs NDJSON format.\"\"\"\n",
        "    vertexai.init(project=project_id, location=location)\n",
        "    model = GenerativeModel(model_name)\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    blobs = storage_client.list_blobs(bucket_name, prefix=raw_folder)\n",
        "\n",
        "    for blob in blobs:\n",
        "        if blob.name == raw_folder:\n",
        "            continue  # Skip folder itself\n",
        "\n",
        "        # Generate correct NDJSON file path\n",
        "        json_filename = Path(llm_folder) / (Path(blob.name).stem + \".jsonl\")  # Using .jsonl for NDJSON\n",
        "        print(f\"Saving NDJSON file to: {json_filename}\")\n",
        "\n",
        "        # Skip if already processed\n",
        "        if json_filename.exists():\n",
        "            print(f\"{json_filename} already exists, skipping...\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Processing {blob.name}...\")\n",
        "        file_content = Part.from_uri(f\"gs://{bucket_name}/{blob.name}\", \"application/pdf\")\n",
        "        resp = model.generate_content([file_content, prompt])\n",
        "\n",
        "        # Remove any extraneous Markdown artifacts\n",
        "        resp_text = resp.text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "        raw_lines = resp_text.split(\"\\n\")  # Split response line by line\n",
        "\n",
        "        # Ensure folder exists\n",
        "        json_filename.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        valid_json_lines = []\n",
        "\n",
        "        for line in raw_lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue  # Skip empty lines\n",
        "\n",
        "            try:\n",
        "                json_obj = json.loads(line)  # Parse each line separately\n",
        "                valid_json_lines.append(json.dumps(json_obj))  # Store valid JSON strings\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"⚠️ Skipping malformed JSON line: {line}\")\n",
        "\n",
        "        if not valid_json_lines:\n",
        "            print(f\"❌ Error: No valid JSON extracted for {blob.name}. Skipping file.\")\n",
        "            continue  # Move to next file without saving invalid data\n",
        "\n",
        "        # Save as newline-delimited JSON (NDJSON)\n",
        "        with open(json_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"\\n\".join(valid_json_lines) + \"\\n\")  # Write valid JSON objects line by line\n",
        "\n",
        "        print(f\"✅ Successfully saved NDJSON: {json_filename}\")\n",
        "\n",
        "def copy_to_GCS(local_folder, gcs_folder, file_extension):\n",
        "    \"\"\"Uploads all processed JSONL files to Google Cloud Storage.\"\"\"\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "    directory_as_path_obj = Path(local_folder).resolve()\n",
        "    print(f\"Checking for JSONL files in: {directory_as_path_obj}\")\n",
        "\n",
        "    file_paths = list(directory_as_path_obj.rglob(file_extension))\n",
        "    print(f\"Found JSONL files: {file_paths}\")\n",
        "\n",
        "    if not file_paths:\n",
        "        print(f\"⚠️ No JSONL files found in {local_folder}, skipping upload.\")\n",
        "        return\n",
        "\n",
        "    correct_gcs_folder = gcs_folder.rstrip(\"/\") + \"/\"\n",
        "\n",
        "    results = transfer_manager.upload_many_from_filenames(\n",
        "        bucket,\n",
        "        [str(f.relative_to(directory_as_path_obj)) for f in file_paths],\n",
        "        source_directory=str(directory_as_path_obj),\n",
        "        blob_name_prefix=correct_gcs_folder,\n",
        "        max_workers=5\n",
        "    )\n",
        "\n",
        "    for name, result in zip(file_paths, results):\n",
        "        if isinstance(result, Exception):\n",
        "            print(f\"⚠️ Failed to upload {name} due to {result}\")\n",
        "        else:\n",
        "            print(f\"✅ Uploaded {name} to {bucket.name}/{correct_gcs_folder}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    extract()  # Process ALL PDFs and convert to NDJSON\n",
        "    copy_to_GCS(llm_folder, llm_folder, \"*.jsonl\")  # Upload ALL JSONL files\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving NDJSON file to: initial-loads/ccus_facility/llm_text/CCSMap25.jsonl\n",
            "Processing initial-loads/ccus_facility/raw/CCSMap25.pdf...\n",
            "⚠️ Skipping malformed JSON line: {\"id\": 136, \"facility\": \"Natural Gas\", \"organization\": \"Natural Gas\", \"city\": \"Cotton Cove\", \"state\": \"TX\", \"category\": \"Capture, Storage\", \"status\": \"Operational\", \"industry\": \"Natural Gas\n",
            "✅ Successfully saved NDJSON: initial-loads/ccus_facility/llm_text/CCSMap25.jsonl\n",
            "Checking for JSONL files in: /content/initial-loads/ccus_facility/llm_text\n",
            "Found JSONL files: [PosixPath('/content/initial-loads/ccus_facility/llm_text/CCSMap25.jsonl')]\n",
            "✅ Uploaded /content/initial-loads/ccus_facility/llm_text/CCSMap25.jsonl to us_climate/initial-loads/ccus_facility/llm_text/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OstOQXEAzz5t"
      },
      "id": "OstOQXEAzz5t",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": " 1-us_climate-extract-ccus_facility.ipynb"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}